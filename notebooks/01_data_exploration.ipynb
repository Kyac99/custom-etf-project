{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration des Données pour l'ETF Personnalisé\n",
    "\n",
    "Ce notebook réalise une exploration des données financières pour la construction d'un ETF personnalisé ciblant les marchés émergents et les technologies.\n",
    "\n",
    "## Objectifs\n",
    "- Explorer les données de marché des actifs potentiels pour l'ETF\n",
    "- Analyser les caractéristiques fondamentales des actifs\n",
    "- Examiner les métriques de liquidité\n",
    "- Visualiser les corrélations entre actifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Imports nécessaires\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configuration pour les visualisations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "# Définir les chemins de données\n",
    "data_dir = Path(\"../data\")\n",
    "raw_dir = data_dir / \"raw\"\n",
    "processed_dir = data_dir / \"processed\"\n",
    "config_path = Path(\"../config/config.yaml\")\n",
    "\n",
    "# Créer les répertoires s'ils n'existent pas\n",
    "raw_dir.mkdir(parents=True, exist_ok=True)\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement de la Configuration\n",
    "\n",
    "Commençons par charger la configuration du projet depuis le fichier YAML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Charger la configuration\n",
    "try:\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "        print(\"Configuration chargée avec succès!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement de la configuration: {e}\")\n",
    "    # Créer une configuration par défaut si le fichier n'existe pas\n",
    "    config = {\n",
    "        \"etf\": {\n",
    "            \"name\": \"Innovation Tech Émergente ETF\",\n",
    "            \"benchmark\": \"MSCI Emerging Markets Technology Index\"\n",
    "        },\n",
    "        \"asset_selection\": {\n",
    "            \"markets\": [\"Brazil\", \"Russia\", \"India\", \"China\", \"South Africa\"],\n",
    "            \"sectors\": [\"Technology\", \"Telecommunications\", \"Consumer Electronics\"]\n",
    "        },\n",
    "        \"backtesting\": {\n",
    "            \"start_date\": \"2018-01-01\",\n",
    "            \"end_date\": \"2022-12-31\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Afficher les informations de base sur l'ETF\n",
    "print(f\"Nom de l'ETF: {config['etf']['name']}\")\n",
    "print(f\"Indice de référence: {config['etf']['benchmark']}\")\n",
    "print(f\"\\nMarchés ciblés: {', '.join(config['asset_selection']['markets'])}\")\n",
    "print(f\"Secteurs ciblés: {', '.join(config['asset_selection']['sectors'])}\")\n",
    "print(f\"\\nPériode de backtest: {config['backtesting']['start_date']} à {config['backtesting']['end_date']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecte des Données de Marché\n",
    "\n",
    "Pour notre ETF, nous avons besoin de données de marché pour les actifs des pays émergents ciblés. Commençons par identifier les ETFs les plus connus pour ces marchés afin d'extraire leurs composants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Définir les ETFs représentatifs pour chaque marché\n",
    "market_etfs = {\n",
    "    \"Brazil\": \"EWZ\",\n",
    "    \"Russia\": \"RSX\",\n",
    "    \"India\": \"INDA\",\n",
    "    \"China\": \"MCHI\",\n",
    "    \"South Africa\": \"EZA\",\n",
    "    \"Mexico\": \"EWW\",\n",
    "    \"Indonesia\": \"EIDO\",\n",
    "    \"Turkey\": \"TUR\"\n",
    "}\n",
    "\n",
    "# Récupérer des informations sur ces ETFs\n",
    "for market, etf_ticker in market_etfs.items():\n",
    "    try:\n",
    "        etf = yf.Ticker(etf_ticker)\n",
    "        info = etf.info\n",
    "        print(f\"{market} - {etf_ticker}: {info.get('longName', 'N/A')}\")\n",
    "        print(f\"  Actifs sous gestion: {info.get('totalAssets', 'N/A'):,}\")\n",
    "        print(f\"  Description: {info.get('longBusinessSummary', 'N/A')[:150]}...\")\n",
    "        print(\"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la récupération des informations pour {etf_ticker}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des Composants des ETFs Existants\n",
    "\n",
    "Examinons la composition des ETFs pour identifier les entreprises potentielles pour notre ETF personnalisé, en se concentrant sur les secteurs technologiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Créer un dictionnaire pour stocker les composants par marché\n",
    "market_components = {}\n",
    "\n",
    "# Boucler sur chaque ETF de marché\n",
    "for market, etf_ticker in market_etfs.items():\n",
    "    try:\n",
    "        print(f\"Récupération des composants pour {market} ({etf_ticker})...\")\n",
    "        etf = yf.Ticker(etf_ticker)\n",
    "        holdings = etf.get_holdings()\n",
    "        \n",
    "        if holdings is not None and not holdings.empty:\n",
    "            # Filtrer les secteurs technologiques\n",
    "            tech_keywords = ['tech', 'software', 'hardware', 'semiconductor', 'telecom', \n",
    "                           'communication', 'electronics', 'internet', 'media', 'digital']\n",
    "            \n",
    "            tech_holdings = holdings[holdings['Sector'].str.lower().str.contains('|'.join(tech_keywords), na=False)]\n",
    "            \n",
    "            print(f\"  Nombre total de composants: {len(holdings)}\")\n",
    "            print(f\"  Nombre de composants tech: {len(tech_holdings)}\")\n",
    "            \n",
    "            # Afficher les 5 plus grandes entreprises tech\n",
    "            if not tech_holdings.empty:\n",
    "                print(\"\\n  Top 5 entreprises tech par poids:\")\n",
    "                top5 = tech_holdings.sort_values('% of ETF', ascending=False).head(5)\n",
    "                for idx, row in top5.iterrows():\n",
    "                    print(f\"    {row['Name']} ({row['Ticker']}) - {row['Sector']} - {row['% of ETF']:.2%}\")\n",
    "                \n",
    "                # Stocker les composants tech\n",
    "                market_components[market] = tech_holdings\n",
    "            else:\n",
    "                print(\"  Aucune entreprise tech trouvée dans cet ETF.\")\n",
    "        else:\n",
    "            print(f\"  Pas de données de holdings disponibles pour {etf_ticker}\")\n",
    "        \n",
    "        print(\"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la récupération des holdings pour {etf_ticker}: {e}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration des Prix Historiques\n",
    "\n",
    "Récupérons les prix historiques pour quelques-unes des entreprises technologiques les plus importantes de chaque marché."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Créer une liste des tickers technologiques les plus importants\n",
    "top_tech_tickers = []\n",
    "\n",
    "for market, holdings in market_components.items():\n",
    "    if not holdings.empty:\n",
    "        # Prendre les 3 plus grands tickers tech par marché\n",
    "        top3 = holdings.sort_values('% of ETF', ascending=False).head(3)\n",
    "        for ticker in top3['Ticker']:\n",
    "            if ticker not in top_tech_tickers and pd.notna(ticker):\n",
    "                top_tech_tickers.append(ticker)\n",
    "\n",
    "print(f\"Nombre de tickers tech sélectionnés: {len(top_tech_tickers)}\")\n",
    "print(f\"Tickers: {', '.join(top_tech_tickers)}\")\n",
    "\n",
    "# Récupérer les prix historiques\n",
    "start_date = config['backtesting']['start_date']\n",
    "end_date = config['backtesting']['end_date']\n",
    "\n",
    "print(f\"\\nRécupération des prix historiques du {start_date} au {end_date}...\")\n",
    "\n",
    "try:\n",
    "    # Télécharger les prix\n",
    "    prices_df = yf.download(top_tech_tickers, start=start_date, end=end_date, auto_adjust=True)['Close']\n",
    "    \n",
    "    # Afficher les informations sur les données de prix\n",
    "    print(f\"Données de prix récupérées: {prices_df.shape[0]} jours pour {prices_df.shape[1]} tickers\")\n",
    "    \n",
    "    # Sauvegarder les données de prix\n",
    "    prices_path = raw_dir / \"selected_prices.parquet\"\n",
    "    prices_df.to_parquet(prices_path)\n",
    "    print(f\"Données de prix sauvegardées dans {prices_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de la récupération des prix: {e}\")\n",
    "    prices_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des Performances Historiques\n",
    "\n",
    "Examinons les performances historiques des actifs sélectionnés pour avoir une idée des tendances et des volatilités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if not prices_df.empty:\n",
    "    # Calculer les rendements cumulés\n",
    "    returns = prices_df.pct_change()\n",
    "    cumulative_returns = (1 + returns).cumprod() - 1\n",
    "    \n",
    "    # Visualiser les rendements cumulés\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    cumulative_returns.plot()\n",
    "    plt.title('Rendements Cumulés des Actifs Tech des Marchés Émergents', fontsize=16)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Rendement Cumulé (%)')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculer les statistiques de performance\n",
    "    perf_stats = pd.DataFrame({\n",
    "        'Rendement Total': cumulative_returns.iloc[-1],\n",
    "        'Rendement Annualisé': (1 + cumulative_returns.iloc[-1]) ** (252 / len(cumulative_returns)) - 1,\n",
    "        'Volatilité Annualisée': returns.std() * np.sqrt(252),\n",
    "        'Ratio de Sharpe': (returns.mean() - 0.02/252) / (returns.std()) * np.sqrt(252),\n",
    "        'Drawdown Maximum': ((1 + returns).cumprod().div((1 + returns).cumprod().cummax()) - 1).min()\n",
    "    })\n",
    "    \n",
    "    # Afficher les statistiques triées par rendement annualisé\n",
    "    perf_stats = perf_stats.sort_values('Rendement Annualisé', ascending=False)\n",
    "    display(perf_stats.style.format({\n",
    "        'Rendement Total': '{:.2%}',\n",
    "        'Rendement Annualisé': '{:.2%}',\n",
    "        'Volatilité Annualisée': '{:.2%}',\n",
    "        'Ratio de Sharpe': '{:.2f}',\n",
    "        'Drawdown Maximum': '{:.2%}'\n",
    "    }))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Combiné pour la Sélection des Actifs\n",
    "\n",
    "Créons un score combiné pour classifier les actifs en fonction de plusieurs critères importants pour notre ETF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if 'fundamentals_df' in locals() and not fundamentals_df.empty and not prices_df.empty:\n",
    "    # Créer un DataFrame pour le scoring\n",
    "    scoring_df = fundamentals_df[['Ticker', 'Nom', 'Pays', 'Secteur']].copy()\n",
    "    \n",
    "    # Ajouter les métriques de performance\n",
    "    if 'perf_stats' in locals():\n",
    "        for ticker in scoring_df['Ticker']:\n",
    "            if ticker in perf_stats.index:\n",
    "                scoring_df.loc[scoring_df['Ticker'] == ticker, 'Rendement Annualisé'] = perf_stats.loc[ticker, 'Rendement Annualisé']\n",
    "                scoring_df.loc[scoring_df['Ticker'] == ticker, 'Volatilité'] = perf_stats.loc[ticker, 'Volatilité Annualisée']\n",
    "                scoring_df.loc[scoring_df['Ticker'] == ticker, 'Ratio de Sharpe'] = perf_stats.loc[ticker, 'Ratio de Sharpe']\n",
    "    \n",
    "    # Ajouter les métriques fondamentales\n",
    "    scoring_df['Marge Bénéficiaire'] = fundamentals_df['Marge Bénéficiaire']\n",
    "    scoring_df['ROE'] = fundamentals_df['ROE']\n",
    "    scoring_df['Croissance des Revenus'] = fundamentals_df['Croissance des Revenus']\n",
    "    scoring_df['Capitalisation Boursière'] = fundamentals_df['Capitalisation Boursière']\n",
    "    \n",
    "    # Ajouter les métriques de liquidité\n",
    "    if 'liquidity_df' in locals() and not liquidity_df.empty:\n",
    "        for ticker in scoring_df['Ticker']:\n",
    "            if ticker in liquidity_df.index:\n",
    "                scoring_df.loc[scoring_df['Ticker'] == ticker, 'Volume Quotidien Moyen'] = liquidity_df.loc[ticker, 'Volume Quotidien Moyen']\n",
    "                scoring_df.loc[scoring_df['Ticker'] == ticker, 'Stabilité du Volume'] = liquidity_df.loc[ticker, 'Stabilité du Volume (CV)']\n",
    "    \n",
    "    # Normaliser les métriques pour le scoring (min-max scaling)\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "    metrics_to_normalize = [\n",
    "        'Rendement Annualisé', 'Volatilité', 'Ratio de Sharpe', 'Marge Bénéficiaire', 'ROE', \n",
    "        'Croissance des Revenus', 'Capitalisation Boursière', 'Volume Quotidien Moyen', 'Stabilité du Volume'\n",
    "    ]\n",
    "    \n",
    "    for metric in metrics_to_normalize:\n",
    "        if metric in scoring_df.columns:\n",
    "            # Remplacer les valeurs manquantes par la médiane\n",
    "            scoring_df[metric] = scoring_df[metric].fillna(scoring_df[metric].median())\n",
    "            \n",
    "            # Pour certaines métriques, une valeur plus faible est meilleure (volatilité, stabilité du volume)\n",
    "            if metric in ['Volatilité', 'Stabilité du Volume']:\n",
    "                scoring_df[f'{metric}_Score'] = 1 - MinMaxScaler().fit_transform(scoring_df[metric].values.reshape(-1, 1)).flatten()\n",
    "            else:\n",
    "                scoring_df[f'{metric}_Score'] = MinMaxScaler().fit_transform(scoring_df[metric].values.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # Calculer un score combiné (avec différentes pondérations selon l'importance des critères)\n",
    "    scoring_df['Score_Performance'] = (scoring_df.get('Rendement Annualisé_Score', 0) * 0.4 + \n",
    "                                     scoring_df.get('Volatilité_Score', 0) * 0.3 + \n",
    "                                     scoring_df.get('Ratio de Sharpe_Score', 0) * 0.3)\n",
    "    \n",
    "    scoring_df['Score_Fondamental'] = (scoring_df.get('Marge Bénéficiaire_Score', 0) * 0.3 + \n",
    "                                     scoring_df.get('ROE_Score', 0) * 0.3 + \n",
    "                                     scoring_df.get('Croissance des Revenus_Score', 0) * 0.4)\n",
    "    \n",
    "    scoring_df['Score_Liquidité'] = (scoring_df.get('Capitalisation Boursière_Score', 0) * 0.3 + \n",
    "                                   scoring_df.get('Volume Quotidien Moyen_Score', 0) * 0.5 + \n",
    "                                   scoring_df.get('Stabilité du Volume_Score', 0) * 0.2)\n",
    "    \n",
    "    # Score final pondéré\n",
    "    scoring_df['Score_Final'] = (scoring_df['Score_Performance'] * 0.4 + \n",
    "                               scoring_df['Score_Fondamental'] * 0.4 + \n",
    "                               scoring_df['Score_Liquidité'] * 0.2)\n",
    "    \n",
    "    # Trier par score final\n",
    "    scoring_df = scoring_df.sort_values('Score_Final', ascending=False)\n",
    "    \n",
    "    # Afficher les meilleurs scores\n",
    "    print(\"Top 15 Actifs par Score Final:\")\n",
    "    display(scoring_df[['Ticker', 'Nom', 'Pays', 'Secteur', 'Score_Performance', \n",
    "                       'Score_Fondamental', 'Score_Liquidité', 'Score_Final']].head(15))\n",
    "    \n",
    "    # Sauvegarder les scores\n",
    "    scores_path = processed_dir / \"asset_scores.parquet\"\n",
    "    scoring_df.to_parquet(scores_path)\n",
    "    print(f\"Scores des actifs sauvegardés dans {scores_path}\")\n",
    "    \n",
    "    # Visualiser les scores\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    top10 = scoring_df.head(10)\n",
    "    scores = top10[['Score_Performance', 'Score_Fondamental', 'Score_Liquidité']]\n",
    "    \n",
    "    # Créer un graphique à barres empilées\n",
    "    scores.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "    plt.title('Décomposition des Scores pour les 10 Meilleurs Actifs', fontsize=16)\n",
    "    plt.xlabel('Ticker')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xticks(range(len(top10)), top10['Ticker'], rotation=45)\n",
    "    plt.grid(True, axis='y')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion et Prochaines Étapes\n",
    "\n",
    "Dans ce notebook, nous avons exploré les données pour notre ETF personnalisé ciblant les technologies des marchés émergents. \n",
    "\n",
    "### Résumé des Observations\n",
    "- Nous avons identifié les principales entreprises technologiques des marchés émergents\n",
    "- Nous avons analysé leurs performances historiques, volatilité et liquidité\n",
    "- Nous avons examiné leurs fondamentaux et créé un système de scoring pour évaluer les actifs\n",
    "\n",
    "### Prochaines Étapes\n",
    "1. **Sélection finale des actifs** - Utiliser le système de scoring et appliquer des filtres supplémentaires selon la stratégie\n",
    "2. **Pondération du portefeuille** - Implémenter différentes méthodes de pondération (capitalisation, égale, fondamentale)\n",
    "3. **Backtesting** - Tester la performance historique de l'ETF avec différentes configurations\n",
    "4. **Analyse des coûts** - Évaluer les coûts de transaction et l'impact sur la performance\n",
    "5. **Analyse de l'impact sur la liquidité** - Évaluer l'impact potentiel de l'ETF sur la liquidité du marché\n",
    "\n",
    "Les résultats de cette exploration seront utilisés dans les prochains notebooks pour construire et tester notre ETF personnalisé."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}